{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b027e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from selenium.webdriver.edge.service import Service as EdgeService\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from google.oauth2 import service_account\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import pandas_gbq as pg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import db_dtypes\n",
    "import requests\n",
    "import datetime\n",
    "import socket\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "# https://docs.google.com/spreadsheets/d/1FHMiINu9_3KSEuconyMFQWsO6K9MbM9W6xlbXC2QR0Q/edit?gid=0#gid=0\n",
    "\n",
    "# Define the Google Sheets document ID\n",
    "sheet_id = '1FHMiINu9_3KSEuconyMFQWsO6K9MbM9W6xlbXC2QR0Q'\n",
    "\n",
    "# Load the data from the specified Google Sheets document into a pandas DataFrame\n",
    "xls = pd.ExcelFile(f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=xlsx\")\n",
    "Url_List = pd.read_excel(xls, 'URL Input Sheet ')\n",
    "\n",
    "# Prepare URL DataFrame\n",
    "url_df = Url_List\n",
    "url_df['index'] = url_df.index\n",
    "url_df['Rand_Num'] = url_df.index.to_series().apply(lambda x: f\"?{1000 + x}\")  # to clear chache referesh the website \n",
    "url_df['New_Url'] = url_df['Url'] + url_df['Rand_Num']\n",
    "url_lstt = url_df.values\n",
    "\n",
    "# Initialize DataFrame to collect results and list to collect failed URLs\n",
    "data_df = pd.DataFrame()\n",
    "failed_urls = []\n",
    "\n",
    "# Initialize WebDriver for Chrome\n",
    "driver_path = r'C:\\Users\\Maaz Shaikh\\chromedriver-win64\\chromedriver.exe'\n",
    "service = Service(driver_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Loop through each URL in the list and scrape price data\n",
    "for i in url_lstt:\n",
    "    Price = None\n",
    "\n",
    "    # Handling different sources (e.g., Tatacliq, Amazon, Flipkart, etc.)\n",
    "    if i[2] == \"Tatacliq\":\n",
    "        try:\n",
    "            driver.get(i[5])\n",
    "            time.sleep(2)  # Wait for the page to load\n",
    "            text_field = driver.find_element(By.XPATH, '//*[@id=\"BPDT\"]/div[1]/div[2]/div[1]/div[1]/h3')\n",
    "            Price = text_field.text\n",
    "        except:\n",
    "            try:\n",
    "                driver.get(i[5])\n",
    "                time.sleep(2)\n",
    "                text_field = driver.find_element(By.XPATH, '//*[@id=\"app\"]/div[2]/div/div/div[1]/div[2]/div[1]/div[1]/div[2]')                             \n",
    "                Price = text_field.text\n",
    "            except:\n",
    "                failed_urls.append(i[1])\n",
    "\n",
    "    elif i[2] == \"Amazon\":\n",
    "        try:\n",
    "            driver.get(i[5])\n",
    "            time.sleep(2)\n",
    "            text_field = driver.find_element(By.XPATH, '//span[text()=\" Currently unavailable. \"]')\n",
    "            Price = text_field.text\n",
    "        except:\n",
    "            try:\n",
    "                driver.get(i[5])\n",
    "                time.sleep(2)\n",
    "                text_field = driver.find_element(By.XPATH, '(//span[@class=\"a-price-whole\"])[1]')\n",
    "                Price = text_field.text\n",
    "            except:\n",
    "                try:\n",
    "                    driver.get(i[5])\n",
    "                    time.sleep(2)\n",
    "                    text_field = driver.find_element(By.XPATH, '//*[@id=\"corePrice_feature_div\"]/div/div/span[1]/span[2]/span[2]')\n",
    "                    Price = text_field.text\n",
    "                except:\n",
    "                    failed_urls.append(i[1])\n",
    "\n",
    "    elif i[2] == \"Flipkart\":\n",
    "        try:\n",
    "            driver.get(i[5])\n",
    "            time.sleep(5)  # Longer wait time as Flipkart might take more time to load\n",
    "            text_field = driver.find_element(By.XPATH, '//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[2]/div[1]/div/div')\n",
    "            Price = text_field.text\n",
    "        except:\n",
    "            try:\n",
    "                driver.get(i[5])\n",
    "                time.sleep(2)\n",
    "                text_field = driver.find_element(By.XPATH, '//div//div[@class=\"Nx9bqj CxhGGd\"]')\n",
    "                Price = text_field.text\n",
    "            except:\n",
    "                failed_urls.append(i[1])\n",
    "\n",
    "    elif i[2] == \"Ajio\":\n",
    "        try:\n",
    "            driver.get(i[5])\n",
    "            time.sleep(2)\n",
    "            text_field = driver.find_element(By.XPATH, '//div//div[@class=\"prod-sp\"]')\n",
    "            Price = text_field.text\n",
    "        except:\n",
    "            try:\n",
    "                driver.get(i[5])\n",
    "                time.sleep(2)\n",
    "                text_field = driver.find_element(By.XPATH, '//*[@id=\"appContainer\"]/div[2]/div/div/div[2]/div/div[3]/div/div[2]/div')\n",
    "                Price = text_field.text\n",
    "            except:\n",
    "                failed_urls.append(i[1])\n",
    "\n",
    "    elif i[2] == \"Myntra\":\n",
    "        try:\n",
    "            driver.get(i[5])\n",
    "            time.sleep(2)\n",
    "            text_field = driver.find_element(By.XPATH, '//*[@id=\"mountRoot\"]/div/div[1]/main/div[2]/div[2]/div[1]/div/p[1]/span[1]')\n",
    "            Price = text_field.text\n",
    "        except:\n",
    "            try:\n",
    "                driver.get(i[5])\n",
    "                time.sleep(2)\n",
    "                text_field = driver.find_element(By.XPATH, '//span[@class=\"pdp-price\"]')\n",
    "                Price = text_field.text\n",
    "            except:\n",
    "                failed_urls.append(i[1])\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Unsupported source\")\n",
    "        continue\n",
    "\n",
    "    # Create a dictionary for the current entry and append it to the results DataFrame\n",
    "    dictt = {\n",
    "        \"Sr_No\": i[3],\n",
    "        \"Brand\": i[0],\n",
    "        \"Url\": i[1],\n",
    "        \"Price\": Price,\n",
    "        \"Source\": i[2]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(dictt, index=[0])\n",
    "    data_df = pd.concat([data_df, df], axis=0)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Get the local machine's hostname and IP address\n",
    "hostname = socket.gethostname()\n",
    "IPAddr = socket.gethostbyname(hostname)\n",
    "\n",
    "# Define Google Cloud credentials\n",
    "key_path = {\n",
    "    \"type\": \"\",\n",
    "    \"project_id\": \"\",\n",
    "    \"private_key_id\": \"\",\n",
    "    \"private_key\": \"\",\n",
    "    \"client_email\": \"\",\n",
    "    \"client_id\": \"\",\n",
    "    \"auth_uri\": \"\",\n",
    "    \"token_uri\": \"\",\n",
    "    \"auth_provider_x509_cert_url\": \"\",\n",
    "    \"client_x509_cert_url\": \"\",\n",
    "    \"universe_domain\": \"\"\n",
    "}\n",
    "\n",
    "# Set up Google Cloud BigQuery client\n",
    "credentials = service_account.Credentials.from_service_account_info(\n",
    "    key_path,\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    ")\n",
    "\n",
    "client = bigquery.Client(\n",
    "    credentials=credentials,\n",
    "    project=credentials.project_id\n",
    ")\n",
    "\n",
    "# Convert the DataFrame to string type and upload it to Google BigQuery\n",
    "data_df = data_df.astype(\"string\")\n",
    "pg.to_gbq(data_df, 'Dummy_Dataset.image_link_price', project_id=\"XYZ\", if_exists='append', credentials=credentials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
